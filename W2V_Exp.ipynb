{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "\n",
    "from Audio_CRNN import *\n",
    "from Lyric_NN import *\n",
    "from Training_Callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATASET:\n",
    "    New_x_train = 'New_x_train.json'\n",
    "    New_y_train = 'New_y_train.json'\n",
    "    New_x_test = 'New_x_test.json'\n",
    "    New_y_test = 'New_y_test.json'\n",
    "    New_x_val = 'New_x_val.json'\n",
    "    New_y_val = 'New_y_val.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import codecs\n",
    "import numpy as np\n",
    "def read_json(filename):\n",
    "    with codecs.open(filename,'r',encoding = 'utf8') as infile:\n",
    "        return np.array(json.load(infile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true,  K.round(y_pred))[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STL(Input_Layers, Feature_Layers, _num_tags):\n",
    "    if len(Feature_Layers) > 1 :\n",
    "        Features = concatenate(Feature_Layers)\n",
    "    else:\n",
    "        Features = Feature_Layers[0]\n",
    "    FC = Dense(_num_tags,kernel_regularizer=regularizers.l2(0.001), activation='sigmoid')(Features)\n",
    "    return Model(inputs=Input_Layers,  outputs=FC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setModel(model_type, audio_method, lyric_method, Audio_kwargs, CRNN_kwargs, Lyric_kwargs, Lyric_CNN, Lyric_RNN, _num_Tags):\n",
    "    if audio_method != '':\n",
    "        audio_input, audio_feature = Audio_NN[audio_method](**Audio_kwargs,**CRNN_kwargs)\n",
    "        #Audio_Model = STL([audio_input], [audio_feature], _num_Tags)\n",
    "    if lyric_method != '':\n",
    "        lyric_input, lyric_feature = Lyric_NN[lyric_method](**Lyric_kwargs, **Lyric_CNN, **Lyric_RNN)\n",
    "        #Lyric_Model = STL([lyric_input], [lyric_feature], _num_Tags)\n",
    "    \n",
    "    if model_type == 'Both':\n",
    "        return_Model = STL([audio_input, lyric_input],[audio_feature, lyric_feature], _num_Tags)\n",
    "        exp_name = '_'.join([model_type, 'Audio', audio_method, 'Lyric', lyric_method])\n",
    "\n",
    "    elif audio_method != '':    #audio only\n",
    "        return_Model = STL([audio_input], [audio_feature], _num_Tags)\n",
    "        exp_name = '_'.join([model_type, 'Audio', audio_method])\n",
    "    else:\n",
    "        return_Model = STL([lyric_input], [lyric_feature], _num_Tags)\n",
    "        exp_name = '_'.join([model_type, 'Lyric', lyric_method])\n",
    "    return return_Model, exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDataGenerator(DG_Type, batchSize, Audio_Collection, Lyric_Collection):\n",
    "    x_train = read_json(DATASET.New_x_train)#[:32]\n",
    "    y_train = read_json(DATASET.New_y_train)#[:32]\n",
    "    x_test = read_json(DATASET.New_x_test)#[:32]\n",
    "    y_test = read_json(DATASET.New_y_test)#[:32]\n",
    "    x_val = read_json(DATASET.New_x_val)#[:32]\n",
    "    y_val = read_json(DATASET.New_y_val)#[:32]\n",
    "    \n",
    "    train_len = (len(x_train)//batchSize)*batchSize\n",
    "    test_len = (len(x_test)//batchSize)*batchSize\n",
    "    val_len = (len(x_val)//batchSize)*batchSize\n",
    "    \n",
    "    if DG_Type == 'Both':\n",
    "        DG_train = Data_Generator[DG_Type](x_train[:train_len], y_train[:train_len], batchSize, Audio_Collection, Lyric_Collection)\n",
    "        DG_test = Data_Generator[DG_Type](x_test[:test_len], y_test[:test_len], batchSize, Audio_Collection, Lyric_Collection)\n",
    "        DG_val = Data_Generator[DG_Type](x_val[:val_len], y_val[:val_len], batchSize, Audio_Collection, Lyric_Collection)\n",
    "    elif DG_Type == 'Audio':\n",
    "        DG_train = Data_Generator[DG_Type](x_train[:train_len], y_train[:train_len], batchSize, Audio_Collection)\n",
    "        DG_test = Data_Generator[DG_Type](x_test[:test_len], y_test[:test_len], batchSize, Audio_Collection)\n",
    "        DG_val = Data_Generator[DG_Type](x_val[:val_len], y_val[:val_len], batchSize, Audio_Collection)\n",
    "    elif DG_Type == 'Lyric':\n",
    "        DG_train = Data_Generator[DG_Type](x_train[:train_len], y_train[:train_len], batchSize, Lyric_Collection)\n",
    "        DG_test = Data_Generator[DG_Type](x_test[:test_len], y_test[:test_len], batchSize, Lyric_Collection)\n",
    "        DG_val = Data_Generator[DG_Type](x_val[:val_len], y_val[:val_len], batchSize, Lyric_Collection)\n",
    "    \n",
    "    DG = {\n",
    "        'train': DG_train,\n",
    "        'test': DG_test,\n",
    "        'val': DG_val\n",
    "    }\n",
    "    \n",
    "    return DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDataGenerator(DG_Type, batchSize, Audio_Collection, Lyric_Collection):\n",
    "    x_train = read_json(DATASET.New_x_train)#[:32]\n",
    "    y_train = read_json(DATASET.New_y_train)#[:32]\n",
    "    x_test = read_json(DATASET.New_x_test)#[:32]\n",
    "    y_test = read_json(DATASET.New_y_test)#[:32]\n",
    "    x_val = read_json(DATASET.New_x_val)#[:32]\n",
    "    y_val = read_json(DATASET.New_y_val)#[:32]\n",
    "    \n",
    "    train_len = (len(x_train)//batchSize)*batchSize\n",
    "    test_len = (len(x_test)//batchSize)*batchSize\n",
    "    val_len = (len(x_val)//batchSize)*batchSize\n",
    "    \n",
    "    if DG_Type == 'Both':\n",
    "        DG_train = Data_Generator[DG_Type](x_train[:train_len], y_train[:train_len], batchSize, Audio_Collection, Lyric_Collection)\n",
    "        DG_test = Data_Generator[DG_Type](x_test[:test_len], y_test[:test_len], batchSize, Audio_Collection, Lyric_Collection)\n",
    "        DG_val = Data_Generator[DG_Type](x_val[:val_len], y_val[:val_len], batchSize, Audio_Collection, Lyric_Collection)\n",
    "    elif DG_Type == 'Audio':\n",
    "        DG_train = Data_Generator[DG_Type](x_train[:train_len], y_train[:train_len], batchSize, Audio_Collection)\n",
    "        DG_test = Data_Generator[DG_Type](x_test[:test_len], y_test[:test_len], batchSize, Audio_Collection)\n",
    "        DG_val = Data_Generator[DG_Type](x_val[:val_len], y_val[:val_len], batchSize, Audio_Collection)\n",
    "    elif DG_Type == 'Lyric':\n",
    "        DG_train = Data_Generator[DG_Type](x_train[:train_len], y_train[:train_len], batchSize, Lyric_Collection)\n",
    "        DG_test = Data_Generator[DG_Type](x_test[:test_len], y_test[:test_len], batchSize, Lyric_Collection)\n",
    "        DG_val = Data_Generator[DG_Type](x_val[:val_len], y_val[:val_len], batchSize, Lyric_Collection)\n",
    "    \n",
    "    DG = {\n",
    "        'train': DG_train,\n",
    "        'test': DG_test,\n",
    "        'val': DG_val\n",
    "    }\n",
    "    \n",
    "    return DG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCallbacks(eva_when_train, test_AUC, early_stop, timer, checkpointer, exp_name, batchSize, stopEpcho, DG_test):\n",
    "    Return_Callbacks = []\n",
    "    \n",
    "    y_test = read_json(DATASET.New_y_test)#[:32]\n",
    "    test_len = (len(y_test)//batchSize)*batchSize\n",
    "\n",
    "    \n",
    "    if eva_when_train == 1:\n",
    "        Eva = AUC_Evalu(y_test[:test_len], DG_test, batchSize)\n",
    "        Return_Callbacks.append(Eva)\n",
    "    if test_AUC == 1:\n",
    "        Test_AUC = BestAUC_callback_TF(y_test[:test_len], DG_test, batchSize)\n",
    "        Return_Callbacks.append(Test_AUC)\n",
    "    if early_stop == 1:\n",
    "        early_stopping = EarlyStopping(monitor='AUC_test', mode='max', patience=stopEpcho, verbose=1)\n",
    "        Return_Callbacks.append(early_stopping)\n",
    "    if timer == 1:\n",
    "        time_callback = TimeHistory()\n",
    "        Return_Callbacks.append(time_callback)\n",
    "    if checkpointer == 1:\n",
    "        check_callback_1 = ModelCheckpoint(filepath=os.path.join(exp_name,exp_name+\"_{epoch:02d}-{AUC_Best:.2f}.hdf5\"), mode = 'max', monitor='AUC_Best', verbose=1, save_best_only=True, )\n",
    "        check_callback_2 = ModelCheckpoint(filepath=os.path.join(exp_name,exp_name+\"_{epoch:02d}-{AUC_test:.2f}.hdf5\"), mode = 'max', monitor='AUC_test', verbose=1, save_best_only=True, )\n",
    "        \n",
    "        Return_Callbacks.append(check_callback_1)\n",
    "        Return_Callbacks.append(check_callback_2)\n",
    "\n",
    "    return Return_Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read Data Base\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "uri = \"mongodb://localhost:27017/database\" #mongodb://<user_name>:<user_password>@ds<xxxxxx>.mlab.com:<xxxxx>/<database_name>\n",
    "conn = MongoClient(uri)\n",
    "db = conn.PaperData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['W2V_Self_80_25_100', 'W2V_Re_80_25_100', 'W2V_Pre_80_25_100']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 609s 5s/step - loss: 0.4033 - auc: 0.5077 - val_loss: 0.3503 - val_auc: 0.5040\n",
      "[AUC] Start predict...  [OK]\n",
      "[Total OK!]\n",
      "AUC_test: 0.50062 \n",
      "[AUC] Best AUC calcute...\n",
      "[Tag OK!]\n",
      "AUC_Best: 0.50242 \n",
      "Best AUC Timer : 176.56359 \n",
      "\n",
      "Epoch 00001: AUC_Best improved from -inf to 0.50242, saving model to Lyric_Lyric_RNN_W2V_Pre_80_25_100/Lyric_Lyric_RNN_W2V_Pre_80_25_100_01-0.50.hdf5\n",
      "\n",
      "Epoch 00001: AUC_test improved from -inf to 0.50062, saving model to Lyric_Lyric_RNN_W2V_Pre_80_25_100/Lyric_Lyric_RNN_W2V_Pre_80_25_100_01-0.50.hdf5\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 575s 5s/step - loss: 0.3327 - auc: 0.5031 - val_loss: 0.3250 - val_auc: 0.5027\n",
      "[AUC] Start predict...  [OK]\n",
      "[Total OK!]\n",
      "AUC_test: 0.50017 \n",
      "[AUC] Best AUC calcute...\n",
      "[Tag OK!]\n",
      "AUC_Best: 0.50458 \n",
      "Best AUC Timer : 171.36819 \n",
      "\n",
      "Epoch 00002: AUC_Best improved from 0.50242 to 0.50458, saving model to Lyric_Lyric_RNN_W2V_Pre_80_25_100/Lyric_Lyric_RNN_W2V_Pre_80_25_100_02-0.50.hdf5\n",
      "\n",
      "Epoch 00002: AUC_test did not improve from 0.50062\n",
      "Epoch 3/100\n",
      " 36/116 [========>.....................] - ETA: 6:14 - loss: 0.3198 - auc: 0.5026"
     ]
    }
   ],
   "source": [
    "from joblib import parallel_backend\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    W2V_List = ['W2V_Pre_80_25_100', 'W2V_Re_80_25_100', 'W2V_Self_80_25_100']\n",
    "    for W2V in W2V_List:\n",
    "        Audio_kwargs = {\n",
    "            \"_num_mel_scale\": 96,\n",
    "            \"_num_time_len\": 1366,\n",
    "            \"_num_channel\": 1\n",
    "        }\n",
    "        CRNN_kwargs = {\n",
    "            \"_CL_1_kernal\": 169,\n",
    "            \"_CL_2_kernal\": 339,\n",
    "            \"_CL_3_kernal\": 339,\n",
    "            \"_CL_4_kernal\": 339,\n",
    "            \"_RNN_1_kernal\": 169,\n",
    "            \"_RNN_2_kernal\": 169\n",
    "\n",
    "        }\n",
    "        Lyric_kwargs = {\n",
    "            \"_num_lines\": 80,\n",
    "            \"_num_words\": 25,\n",
    "            \"_num_WEdim\": 100\n",
    "        }\n",
    "        Lyric_CNN = {\n",
    "            \"_num_LyricCNN_kernalSize\": 3, # #CNN Size start from 3\n",
    "            \"_num_LyricCNN_kernalnum\": 100 # for each size of kernal, how many different kernals \n",
    "        }\n",
    "        Lyric_RNN = {\n",
    "            \"_num_WGRU\": 100, # #CNN Size start from 3\n",
    "            \"_num_LGRU\": 200 # for each size of kernal, how many different kernals \n",
    "        }\n",
    "        Model_Setting = {\n",
    "            \"model_type\": 'Lyric',\n",
    "            \"audio_method\": '',\n",
    "            \"lyric_method\": 'RNN',\n",
    "            \"Audio_kwargs\": Audio_kwargs,\n",
    "            \"CRNN_kwargs\": CRNN_kwargs,\n",
    "            \"Lyric_kwargs\": Lyric_kwargs,\n",
    "            \"Lyric_CNN\": Lyric_CNN,\n",
    "            \"Lyric_RNN\": Lyric_RNN,\n",
    "            \"_num_Tags\": 50\n",
    "        }\n",
    "\n",
    "        _epchos = 100\n",
    "        _batchSize = 256\n",
    "\n",
    "        Spectrogram_Collection  =  db.get_collection('MSD_1366')\n",
    "        LineCNN_Collection  =  db.get_collection('Glove_80_25_100')\n",
    "\n",
    "        model, exp_name = setModel(**Model_Setting)\n",
    "\n",
    "        exp_addition_description = '_'+W2V\n",
    "\n",
    "        exp_name = exp_name + exp_addition_description\n",
    "\n",
    "        if not os.path.exists(exp_name):\n",
    "            os.mkdir(exp_name)\n",
    "\n",
    "        DG_Setting = {\n",
    "            \"DG_Type\": Model_Setting['model_type'], \n",
    "            \"batchSize\": _batchSize,\n",
    "            \"Audio_Collection\": db.get_collection('MSD_1366'),\n",
    "            \"Lyric_Collection\": db.get_collection(W2V)\n",
    "        }\n",
    "        DG = setDataGenerator(**DG_Setting)\n",
    "\n",
    "\n",
    "        Callback_Setting = {\n",
    "            \"eva_when_train\": 0,\n",
    "            \"test_AUC\": 1,\n",
    "            \"early_stop\": 1,\n",
    "            \"timer\": 1,\n",
    "            \"checkpointer\": 1,\n",
    "            \"exp_name\": exp_name,\n",
    "            'batchSize':_batchSize,\n",
    "            \"stopEpcho\": 10,\n",
    "            \"DG_test\": DG['test']\n",
    "        }\n",
    "\n",
    "        callbacks = setCallbacks(**Callback_Setting)\n",
    "        \n",
    "        warnings.filterwarnings('ignore')\n",
    "       # with parallel_backend('threading'):\n",
    "        parallel_model = multi_gpu_model(model, gpus=2)\n",
    "        parallel_model.compile(loss=\"binary_crossentropy\",\n",
    "                                  optimizer='adam',\n",
    "                                  metrics=[auc])\n",
    "        History = parallel_model.fit_generator(\n",
    "                    generator=DG['train'],\n",
    "                    steps_per_epoch=DG['train'].step,\n",
    "                    epochs=_epchos,\n",
    "                    verbose=1,\n",
    "                    validation_data=DG['val'],\n",
    "                    validation_steps=DG['val'].step,\n",
    "                    workers=12, \n",
    "                    use_multiprocessing=True,\n",
    "                    callbacks=callbacks\n",
    "                    )\n",
    "        json_string = parallel_model.to_json()\n",
    "        with codecs.open(os.path.join(exp_name, exp_name+'.json'),'w', encoding='utf8') as outfile:\n",
    "            json.dump(json_string,outfile)\n",
    "        with codecs.open(os.path.join(exp_name, exp_name+'_History.json'),'w', encoding='utf8') as outfile:\n",
    "            json.dump(History.history,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
